{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最近用用CNN比较多，梳理一下CNN的发展史，也加深一下对CNN的理解，也给出tensorflow的实现\n",
    "## LeNet-5\n",
    "LeNet是现在广泛使用的CNN的源头。虽然网络规模比较小，但是麻雀虽小，五脏俱全，已经包含了CNN的精华思想。CNN的的特点是卷积层和池化层，卷积层可以看做是提取局部特征，池化层可以看作是压缩特征。随着层数的增加，不断抽象原始的特征，最后达到分类的效果。再提一个细节就是对池化层的理解，最早理解的是采用最大池化是因为卷积神经网络的灵感来源是猫的视觉神经，视觉总是容易被更亮的吸引，所以用最大池化，后来才发现，最大池化其实就是取的无穷范数平均。用数学的角度最大池化平均池化都是某个范数下的平均。这样就为我们打开了一个新的思路，池化层可以有多种选择，可以调整取平均的p范数来尝试优化池化层，但可能池化层所能贡献的精度有限，也没太多人做这方面的工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(inputs, kernel_width, kernel_num, stride, padding, name):\n",
    "    channel = tf.shape(inputs)[-1]\n",
    "    with tf.variable_scope(name):\n",
    "        kernel = tf.get_variable(\"kernel\", [kernel_width, kernel_width, channel, kernel_num])\n",
    "        b = tf.get_variable(\"bias\", [kernel_num])\n",
    "        act = tf.nn.bias_add(tf.nn.conv2d(inputs, kernel, [1, stride, stride, 1], padding=padding, name=\"act\"), b)\n",
    "    return tf.nn.relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(inputs, kernel_width, stride, padding, name):\n",
    "    return tf.nn.max_pool(inputs, [1, kernel_width, kernel_width, 1], [1, stride, stride, 1], padding=padding, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(inputs, out_num, relu, name):\n",
    "    in_num = tf.shape(inputs)[-1]\n",
    "    with tf.variable_scope(name):\n",
    "        W = tf.get_variable(\"weight\", [in_num, out_num])\n",
    "        b = tf.get_variable(\"bias\", [out_num])\n",
    "    if relu:\n",
    "        return tf.nn.relu(tf.matmul(inputs, W)+b)\n",
    "    else:\n",
    "        return tf.matmul(inputs, W)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(inputs, n_class):\n",
    "    x = tf.reshape(inputs, [-1,32,32,1]) #input:32*32*1\n",
    "    \n",
    "    conv1 = conv(x, 5, 6, \"VALID\", \"conv1\") #conv1: 5*5*6 stride=1 -> 28*28*6\n",
    "    pool1 = max_pool(conv1, 2, 2, \"VALID\", \"pool1\") #pool: 2*2 stride=2 -> 14*14*6\n",
    "    \n",
    "    conv2 = conv(x, 5, 16, \"VALID\", \"conv1\") #conv1: 5*5*16 stride=1 -> 10*10*16\n",
    "    pool2 = max_pool(conv1, 2, 2, \"VALID\", \"pool1\") #pool: 2*2 stride=2 -> 5*5*16\n",
    "    \n",
    "    conv2 = conv(x, 5, 120, \"VALID\", \"conv1\") #conv1: 5*5*120 stride=1 -> 1*1*120\n",
    "    flatten = tf.reshape(conv2, [-1, 120]) #flatten conv2 to 1D\n",
    "    \n",
    "    fc1 = fc(flatten, 84, False, \"fc\") #fc1: 120 -> 84\n",
    "    \n",
    "    logit = fc(flatten, 10, False, \"fc\") #fc1: 84 -> 10, Original text using RBF as classifier\n",
    "    \n",
    "    return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet\n",
    "由于算力的有限，CNN的发展并不是很顺利，直到Alex把CNN重新带回大众的视野。与LeNet相比的创新点是：\n",
    "- 1.增加了卷积层的个数\n",
    "- 2.运用了local response normalization\n",
    "- 3.运用了dropout防止过拟合\n",
    "- 4.运用了Relu作为激活函数增加非线性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrn(inputs, depth_radius, bias, alpha, beta, name):\n",
    "    return tf.nn.local_response_normalization(inputs, depth_radius=depth_radius, bias=bias, alpha=alpha, beta=beta, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(inputs, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
