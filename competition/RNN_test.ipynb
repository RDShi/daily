{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime \n",
    "fid = open(\"data/trains.json\")\n",
    "data_raw = json.load(fid)\n",
    "fid.close()\n",
    "start_time = datetime.datetime.strptime(\"2017-10-17\", \"%Y-%m-%d\")\n",
    "feats_raw = []\n",
    "labs = []\n",
    "for data in data_raw:\n",
    "    data_time = datetime.datetime.strptime(data[\"date\"], \"%Y-%m-%d:%H\")\n",
    "    if data_time > start_time:\n",
    "        feats_raw.append([data[\"holiday\"], data[\"week\"]-1, data[\"place\"]-1, data_time.hour])\n",
    "        labs.append(data[\"people\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  7 33 24]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "ohcoder = preprocessing.OneHotEncoder()\n",
    "ohcoder.fit(feats_raw)\n",
    "print(ohcoder.n_values_) # 每个特征对应的最大位数\n",
    "feats = ohcoder.transform(feats_raw).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_feats, val_feats, train_labs, val_labs = train_test_split(feats, labs, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labs = np.reshape(np.array(train_labs),[-1,1]).astype(\"float32\")\n",
    "val_labs = np.reshape(np.array(val_labs),[-1,1]).astype(\"float32\")\n",
    "train_feats = np.reshape(train_feats,[22101, 1,66]).astype(\"float32\")\n",
    "val_feats = np.reshape(val_feats,[-1, 1,66]).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 30\n",
    "NUM_LAYERS = 2\n",
    "TIMESTEPS = 66\n",
    "TRAINING_STEPS = 20000\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(X, y, is_training):\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([\n",
    "        tf.nn.rnn_cell.BasicLSTMCell(HIDDEN_SIZE) \n",
    "        for _ in range(NUM_LAYERS)])\n",
    "\n",
    "    outputs, _ = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "    #output = outputs[:, -1, :]\n",
    "    output = outputs[:, -1, :]\n",
    "\n",
    "    predictions = tf.contrib.layers.fully_connected(\n",
    "        output, 1, activation_fn=None)\n",
    "    \n",
    "    if not is_training:\n",
    "        return predictions, None, None\n",
    "\n",
    "    loss = tf.losses.mean_squared_error(labels=y, predictions=predictions)\n",
    "\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss, tf.train.get_global_step(),\n",
    "        optimizer=\"Adagrad\", learning_rate=0.1)\n",
    "    return predictions, loss, train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(sess, test_X, test_y):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((test_X, test_y))\n",
    "    ds = ds.batch(1)\n",
    "    X, y = ds.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    with tf.variable_scope(\"model\", reuse=True):\n",
    "        prediction, _, _ = lstm_model(X, [0.0], False)\n",
    "    \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for i in range(len(test_y)):\n",
    "        p, l = sess.run([prediction, y])\n",
    "        predictions.append(p)\n",
    "        labels.append(l)\n",
    "\n",
    "    predictions = np.array(predictions).squeeze()\n",
    "    labels = np.array(labels).squeeze()\n",
    "    rmse = np.sqrt(((predictions - labels) ** 2).mean(axis=0))\n",
    "    print(\"Root Mean Square Error is: %f\" % rmse)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(predictions[1], labels[1], color = 'r', s = 20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'IteratorGetNext:0' shape=(?, 1, 66) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICE=5\n",
    "ds = tf.data.Dataset.from_tensor_slices((train_feats, train_labs))\n",
    "ds = ds.repeat().shuffle(50).batch(BATCH_SIZE)\n",
    "X, y = ds.make_one_shot_iterator().get_next()\n",
    "\n",
    "with tf.variable_scope(\"model\"):\n",
    "    _, loss, train_op = lstm_model(X, y, True)\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(TRAINING_STEPS):\n",
    "        _, l = sess.run([train_op, loss])\n",
    "        if i % 1000 == 0:\n",
    "            print(\"train step: \" + str(i) + \", loss: \" + str(l))\n",
    "    \n",
    "    print(\"Evaluate model after training.\")\n",
    "    run_eval(sess, val_feats, val_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
