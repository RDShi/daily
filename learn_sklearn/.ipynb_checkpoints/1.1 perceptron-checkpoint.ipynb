{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 感知机（perceptron）是二分类线性分类模型，是神经网络和支持向量机（SVM）的基础。\n",
    "\n",
    "### MODEL: $f(x)=sign(w^T\\cdot x+b)$, $sign(x)=\\left\\{\\begin{array}{cc} +1, & x\\geq 0\\\\ -1, & x<0\\ values \\end{array}\\right.$\n",
    "\n",
    "### LOSS: $loss=-\\sum_{x_i\\in M}y_i(w^T\\cdot x_i+b)$,$M$是将$x_i$分错类的集合。\n",
    "\n",
    "### OPTIMIZER: Stochastic Gradient Descent, $w_{i+1}=w_{i}+\\eta y_i\\cdot x_i, b_{i+1}=b_{i}+\\eta y_i$ if $x_i \\in M_i$, $\\eta$是步长\n",
    "\n",
    "### THEORY: \n",
    "1.有解性：如果线性可分，那么一定通过SGD一定可以找到解：\n",
    "\n",
    "proof: 为了方便描述，我们将$w^T\\cdot x+b$看作是$w^T\\cdot x$，假设$w_{0}=0$，$||w^*||=1$为解$i.e.y_i w^{*T}\\cdot x_i > \\gamma >0$，$||x||<R$\n",
    "\n",
    "那么有$w^{*T}w_{k+1}=w^{*T}w_{k}+\\eta y_k w^{*T}\\cdot x_k>w^{*T}w_{k}+\\eta\\gamma>k\\eta\\gamma$\n",
    "\n",
    "还有$||w_{k+1}||^2=||w_{k}+\\eta y_k\\cdot x_k||^2<||w_{k}||^2+||\\eta y_k\\cdot x_k||^2 < k\\eta||y_k\\cdot x_k||^2$\n",
    "\n",
    "显然有$||w_{k+1}||>w^{*T}w_{k+1}||$, $i.e.\\ k{\\eta R}^2 > k^2{\\eta\\gamma}^2 \\Longrightarrow k<\\frac{R^2}{\\gamma^2}$，即经过有限步一定可以得到最优解。\n",
    "\n",
    "2.调整次数越多的$x_i$距离分解超平面越近\n",
    "\n",
    "TRICK: 假设$w_{0}=0$，那么$w_{k}=\\sum_{i=0}^{k-1}\\eta y_kx_k=\\sum_{j=0}^{n}\\alpha_jy_kx_k$，$\\alpha_j$是第$j$个样本更新的次数和步长的乘积，那么每次计算$sign(w^T\\cdot x+b)$时，我们可以利用提前计算好的储存好的$x_i^T\\cdot x_j$来加速计算，特别是当维度比较大的时候，加速效果更好。感觉这也是SVM核技巧的思想来源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn中的perceptron介绍\n",
    "class sklearn.linear_model.perceptron\n",
    "可进行多分类，采用的是OVA (One Versus All）策略\n",
    "Parameters:\n",
    "- penalty: regularization term, option: None, ‘l2’ or ‘l1’ or ‘elasticnet’,default=None\n",
    "- alpha : Constant that multiplies the regularization term if regularization is used. Defaults to 0.0001\n",
    "- fit_intercept: 是否有截距b. Defaults to True.\n",
    "- max_iter : 最大迭代epochs数.\n",
    "- tol : 当loss > previous_loss - tol时停止迭代。Defaults to None. Defaults to 1e-3 from 0.21.\n",
    "- shuffle : bool, optional, default True. Whether or not the training data should be shuffled after each epoch.\n",
    "- verbose: integer, 显示详细信息的程度，defaults to 0\n",
    "- eta0: double, 步长, defaults to 1.\n",
    "- n_jobs: integer, 使用CPU的数目，computation. -1 means ‘all CPUs’. Defaults to 1.\n",
    "- random_state: int, 随机种子，default None\n",
    "- class_weight: dict, {class_label: weight} or “balanced” or None, optional. 每一类的权重，如果选“balanced”，则权重与出现的频次乘反比\n",
    "- warm_start : bool, optional. 是否接着上次训练的结果继续训练。\n",
    "\n",
    "Attributes:\n",
    "- coef_ : w的值, shape = [1, n_features] if n_classes == 2 else [n_classes, n_features]\n",
    "- intercept_ : b的值, shape = [1] if n_classes == 2 else [n_classes]\n",
    "- n_iter_ : 迭代次数\n",
    "\n",
    "Methods:\n",
    "- decision_function(X): 相当于求$f(x)=sign(w^T\\cdot x+b)$，二分类返回(n_sample,)，n分类返回(n_sample, n_class)\n",
    "- fit(X, y, coef_init=None, intercept_init=None, sample_weight=None): Fit linear model with Stochastic Gradient Descent.\n",
    "- get_params(deep=True)\tGet parameters for this estimator.\n",
    "- predict(X): Predict class labels for samples in X.\n",
    "- score(X, y[, sample_weight]): 返回acc\n",
    "- set_params(*args, **kwargs)\t\n",
    "- sparsify(), densify(): 把参数稀疏化\n",
    "\n",
    "P.S. Perceptron与SGDClassifier共享底层实现。Perceptron()==SGDClassifier(loss=\"perceptron\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer #乳腺癌\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import acc, make_scorer\n",
    "data = load_breast_cancer()\n",
    "train_feats, val_feats, train_labs, val_labs = train_test_split(data[\"data\"], data[\"target\"], test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.9142857142857143\n",
      "val: 0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "model = Perceptron(penalty=\"l1\", alpha=1)#发现加正则化在验证集上效果会好\n",
    "model = model.fit(train_feats, train_labs)\n",
    "print(\"train:\",model.score(train_feats, train_labs))\n",
    "print(\"val:\",model.score(val_feats, val_labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "score = make_scorer(accuracy_score)\n",
    "\n",
    "model = Perceptron()\n",
    "param_grid = {\"penalty\":[\"l1\",\"l2\"], \"alpha\":[0.01, 0.1, 1, 2]}\n",
    "gsearch = GridSearchCV(model, param_grid, scoring=score)\n",
    "gsearch = gsearch.fit(train_feats, train_labs)\n",
    "print(gsearch.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
